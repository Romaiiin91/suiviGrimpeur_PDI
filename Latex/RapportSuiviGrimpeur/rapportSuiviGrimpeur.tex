\documentclass[a4paper, 11pt, french]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{csquotes}
\usepackage{amsmath,amsfonts,amssymb,mathrsfs}
\usepackage[includeheadfoot, hmargin=2cm, top=0.9cm, bottom = 1.8cm, headsep=2cm]{geometry}
\usepackage{lmodern} %pas pixelisé
\usepackage{engrec,titlesec,lipsum,xcolor}
\usepackage{fancybox}
\usepackage[skins, most]{tcolorbox}
\usepackage[bookmarks={true},bookmarksopen={true}, pdftitle={Cahier des charges}, pdfauthor={Chevalier Romain}, pdfsubject={Caméra domes}, colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=red]{hyperref}
\usepackage{setspace}
\usepackage{stmaryrd}
\usepackage{multicol} 
\usepackage{enumitem}
\usepackage{array,multirow,makecell}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage[bottom]{footmisc}
\usepackage{footnote}
\usepackage[page,header]{appendix}
\usepackage{titletoc}
\makesavenoteenv{tabular}
\makesavenoteenv{table}

\graphicspath{{Figures/}{Photos/}}

\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{decorations.pathmorphing, shapes, automata,positioning}



%-----------------------------------------------------------------------------------

\pagestyle{fancy}
\renewcommand{\headrulewidth}{1pt}
\fancyhead[C]{\leftmark} 
%\fancyhead[R]{\includegraphics[scale=0.13]{logoAdeoService.jpg}}
\fancyhead[R]{\includegraphics[scale=0.1]{Logo_CENTRALE_C.png}}
\newcolumntype{M}{>{\centering\arraybackslash}m{1.75cm}}
\setlength{\headheight}{30.5pt}

%-----------------------------------------------------------------------------------

\frenchbsetup{StandardLists=true}
%\setlength{\parskip}{1em}
\AddThinSpaceBeforeFootnotes
\FrenchFootnotes

%---------------------------------------------------------------

%-----------------------------------------------------------------------------------

\definecolor{vert}{rgb}{0,0.69,0.31}
\definecolor{bleue}{rgb}{0,0.31,0.69} 
\definecolor{violet}{rgb}{0.38,0.18,055} % 97, 45, 140     244, 208, 63
\definecolor{jaune}{rgb}{0.96, 0.85, 0.23}

\definecolor{darkWhite}{rgb}{0.94,0.94,0.94}
\definecolor{vert}{rgb}{0,0.69,0.31}
\definecolor{rose}{rgb}{1,0.08,0.58}% rgb(255,20,147)
\definecolor{rouge}{rgb}{0.78,0.12,0.08}
\definecolor{gris}{rgb}{0.4,0.4,0.4}
\definecolor{marron}{rgb}{0.4,0.2,0}
\definecolor{darkWhite}{rgb}{0.94,0.94,0.94}

%-----------------------------------------------------------------------------------

\title{%
        \Huge Suivi d'un grimpeur par caméra dome \\
        \LARGE Rapport de PDI}

\author{\LARGE CHEVALIER Romain}
\date{\today}

\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

%-----------------------------------------------------------------------------------

\newcounter{obj}
\setcounter{obj}{1}


%-----------------------------------------------------------------------------------


\begin{document}
\pagenumbering{roman}
\begin{titlepage}

    \begin{titlepage}
        \begin{center}
      
          % Upper part of the page. The '~' is needed because \\
          % only works if a paragraph has started.
      
          \textsc{\LARGE École Centrale De Lille}\\[2cm]
      
          \textsc{\huge Projet d'intégration}\\[2cm]
      
          % Title
          \HRule \\[0.4cm]
          { \Huge \bfseries Suivi d'un grimpeur par caméra dome\\[0.4cm] }
      
          \HRule \\[2cm]

          \textsc{\Large Rapport de PDI \\} {\large\today}\\[1.5cm]
          
          \vfill
          % A cahnger pour les caméras installées 
          \includegraphics[width=.8\textwidth]{Figures/cameraQ6304.jpg}
          \vfill

          % Author and supervisor
          \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
              CHEVALIER Romain\\
            \end{flushleft}
          \end{minipage}
          \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
              \emph{Tuteur :}  BOURDEAUD'HUY T. \\
            \end{flushright}
          \end{minipage}
      
          \vspace{1cm}
         
        \end{center}
      \end{titlepage}
    
    \normalsize
   
\end{titlepage}

%-----------------------------------------------------------------------------------

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\startcontents[sections]

%-----------------------------------------------------------------------------------
\tableofcontents
%\printcontents[sections]{l}{1}{\setcounter{tocdepth}{3}}
%\printcontents[sub]{l}{1}{\setcounter{tocdepth}{2}}
\pagenumbering{arabic}
\newpage

%-------------------------------------------------------------

\section{Contexte}
Afin d'améliorer les services offerts aux utilisateurs de la salle d’escalade \textit{Sac à Pof} situé à  Mons-en-Barœul (59), on envisage de mettre en place un système de suivi automatisé des grimpeurs à l'aide de caméras IP dômes motorisées. Ces caméras permettront de suivre les mouvements des grimpeurs sur les différentes voies en ajustant automatiquement le cadrage et le zoom en fonction de leur position. Le services sera accessible via une application web hébergée sur un serveur local. Cette solution vise à offrir un support d'analyse post-session, afin de permettre aux grimpeur de comprendre leurs forces et faiblesses pour s'améliorer.

Afin de réalisé ce projet, nous sommes en possession de deux caméras IP dômes motorisées de la marque \textit{AXIS} modèle \textit{Q6304-E\footnote{Voir \href{https://www.axis.com/dam/public/11/e4/20/cam\%C3\%A9ra-r\%C3\%A9seau-\%C3\%A0-d\%C3\%B4me-ptz-axis-q6034-e-fr-FR-201515.pdf}{fiche technique} pour plus d'informations}}, d'un routeur, d'une tablette Android et d'un raspberry pi 4.

\subsection{Objectifs}
Les objectifs de ce projet sont multiples et sont résumés dans la liste suivante :
\begin{itemize}
  \item Prendre en main les caméras IP dômes motorisées et les intégrer dans un réseau local.
  \item Développer une interface web permettant de piloter les caméras, l'enregistrement de video et leur visualisation.
  \item Avoir un retour visuel de la caméra en temps réel sur l'interface web.
  \item Développer une méthode de communication entre l'application web et les programmes de contrôle des caméras.
  \item Développer un algorithme de suivi de grimpeur en temps réel.
  \item Développer une méthode permettant d'enregister sur un stockage une vidéo.
  \item Avoir une application modulable permettant de modifier les caméra et les paramètres de détection.
\end{itemize}

\section{Architecture du système}
\subsection{Architecture matérielle}
Le système est composé de plusieurs éléments qui interagissent entre eux, la figure \ref{fig:architecture} montre l'architecture du système. Le système repose sur un \textbf{Raspberry Pi 4}, qui joue un rôle central en assurant la communication entre les différentes composantes. Il est connecté au réseau local via un \textbf{routeur}, qui agit comme un serveur DHCP, attribuant dynamiquement les adresses IP aux appareils du système.

Les \textbf{caméras Dome IP} sont accessibles via HTTP et envoient leur flux vidéo vers le Raspberry Pi lorsqu’elles sont activées. Ces caméras disposent de positions prédéfinies correspondant aux différentes voies d’escalade, mais peuvent également être orientées dynamiquement par l’utilisateur via la \textbf{tablette} fournie ou tout autre appareil connecté au réseau local.

Le Raspberry Pi exécute un serveur d’application web,ce serveur permet :
\begin{itemize}
    \item de piloter les caméras (changement de position, orientation manuelle),
    \item de gérer les enregistrements vidéo,
    \item de stocker dans une base de données les vidéos enregistrées ainsi que les positions des caméras définies par l’utilisateur.
\end{itemize}

L’enregistrement des vidéos est déclenché manuellement depuis l’interface de la tablette et les fichiers sont conservés jusqu’à suppression par l’utilisateur.

L’architecture ainsi mise en place assure une gestion centralisée et accessible du système, tout en permettant un contrôle précis et flexible des caméras et des enregistrements.


\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{architectureMaterielle.png}
  \caption{Architecture du système}
  \label{fig:architecture}
\end{figure}

\subsection{Architecture logicielle}
L'architecture logicielle du système est représentée sur la figure \ref{fig:architectureLogicielle}. Le raspberry Pi divise ses tâches en deux parties distinctes : le serveur web et la partie gestion de l'application développée. En fonction des actions effectuées sur la page web, le serveur apache exécuté deux scripts \texttt{cgi} différents, le premier script, nommé \textbf{video.cgi} codé en \texttt{c++}, démarre au chargement de la page permet d'afficher le flux vidéo de la caméra sur la page web en lisant les images brutes dans la mémoire partagée et en les encodant en \texttt{JPEG}. Le second (\textbf{action.cgi} développé en \texttt{c}) permet de transmettre les ordres de déplacement de la caméra ou lancer un enregistrement vidéo via l'écriture de cet ordre dans un segment de mémoire partagé puis de réveillé le programme principal en lui envoyant un signal. 


De l'autre côté, le programme principal (\textbf{main} programmé en \texttt{c}) est en charge de la gestion des caméras, de la détection de mouvement et de l'enregistrement des vidéos. Au démarrage, il crée un processus fils (\textbf{écriture mémoire})qui est en charge de récupérer le flux vidéo du serveur HTTP de la caméra et de le stocker en image brute dans une mémoire partagée. Le programme principal est ensuite en attente d'un signal pour effectuer une action, comme le déplacement de la caméra, l'enregistrement de position ou encore le lancement d'un enregistrement qui va crée un processus fils (\textbf{enregistrement vidéo}) qui encode le flux video en \texttt{MP4} afin de le stocker sur le disque dur et lance la détection du grimpeur pour suivre ces mouvements à l'aide d'un second fils (\textbf{détection}). Ces deux processus récupèrent les images en lisant la mémoire partagée et les traitent pour effectuer leur tâche. Enfin, le programme de détection peut directement agir sur la position de la caméra en lui envoyant une requête HTTP.


\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{architectureLogicielle.png}
  \caption{Architecture logicielle}
  \label{fig:architectureLogicielle}
\end{figure}


%-----------------------------------------------------------

\section{Développement de l'application}
Dans cette partie, nous allons détailler les différentes étapes de développement de l'application pour chaque brique du système présent dans l'architecture logicielle en figure \ref{fig:architectureLogicielle}.

%-----------------------------------------------------------
\subsection{Application système}

La partie système de l'application est composée de plusieurs fichiers et programmes qui interagissent pour gérer les caméras, les enregistrements vidéo et la communication avec l'interface web.

\subsubsection{Programme principal}

Le fichier \texttt{main.c} constitue le cœur du système de gestion des caméras et de la communication inter-processus. Il est responsable de l'initialisation des caméras, de la gestion des enregistrements vidéo, de la détection des mouvements, et de l'interaction avec l'interface CGI via des segments de mémoire partagée et des sémaphores.

\paragraph{Initialisation du programme}
Lors de son démarrage, le programme effectue plusieurs étapes d'initialisation :
\begin{itemize}
    \item \textbf{Gestionnaire de fin d'exécution} : La fonction \texttt{atexit(bye)} garantit que toutes les ressources (mémoire partagée, sémaphores, processus enfants) sont correctement libérées à la fin du programme.
    \item \textbf{Initialisation des sémaphores} : La fonction \texttt{initSemaphores()} crée des sémaphores nommés pour synchroniser les processus et gérer l'accès à la mémoire partagée, voir le paragraphe~\ref{par:semaphores} pour leur fonctionnement.
    \item \textbf{Initialisation de la mémoire partagée} : La fonction \texttt{initSegmentMemoire()} configure deux segments de mémoire partagée : un pour les ordres envoyés par l'interface CGI et un autre pour stocker les images brutes capturées par les caméras.
    \item \textbf{Initialisation des caméras} : La fonction \texttt{initCamera()} charge les paramètres des caméras depuis un fichier JSON et configure les caméras actives. Afin que le système puisse s'adapter à l'orientaiton de la caméra (portrait, paysage, portrait renversé ou paysage renversé), la fonction \texttt{setParamCamera} vient définir les paramètre de la caméra pour que le système puisse s'adapter automatiquement. En effet, on definit le mouvement d'inclinaison et le mouvement panoramique en fonction de l'orientaiton (par exemple, pour le mode paysage un déplacement vers le haut correspond à une augmentation de l'angle d'inclinaison et le mode portrait renverse correspond a une diminution de l'angle panoramique).
\end{itemize}

\paragraph{Gestion des signaux}
Le programme installe un gestionnaire de signaux (\texttt{signalHandler}) pour répondre aux événements suivants :
\begin{itemize}
    \item \textbf{SIGINT} : Interruption manuelle (Ctrl+C) pour arrêter le programme proprement.
    \item \textbf{SIGCHLD} : Gestion des processus enfants terminés pour éviter les processus zombies.
    \item \textbf{SIGUSR1} : Signal utilisé pour indiquer qu'un nouvel ordre a été reçu via la mémoire partagée.
\end{itemize}

\paragraph{Boucle principale}
Le programme entre dans une boucle infinie en appelant \texttt{pause()}, ce qui le met en attente d'un signal. Lorsqu'un signal est reçu, le gestionnaire de signaux (\texttt{signalHandler}) est exécuté pour traiter l'événement.

\paragraph{Gestion des ordres}
Lorsqu'un signal \texttt{SIGUSR1} est reçu, la fonction \texttt{gestionOrdres()} est appelée pour lire et exécuter les ordres envoyés par l'interface CGI. Les types d'ordres gérés incluent :
\begin{itemize}
    \item \textbf{Déplacement de la caméra} : Commandes de mouvement (\texttt{move}) ou de zoom (\texttt{zoom}). Le programme reçoit une direction (haut, bas, gauche, droite) et une valeur de précision pour ajuster l'angle de déplacement (entre 0 et 30 degrés). Il execute ensuite la fonction \texttt{requetePTZ} qui crée une requête HTTP avec l'aide de la librairie \texttt{curl} pour envoyer l'ordre de déplacement à la caméra.
    \item \textbf{Capture vidéo} : Commandes de capture (\texttt{reco}) pour démarrer ou arrêter un processus de capture vidéo. Cet ordre execute la fonction \texttt{enregistrerVideo} qui s'assure que le stockage disponible est suffisant, puis crée le nom de fichier en fonction du nom et prénom du grimpeur, de la voie et de la date et heure de l'enregistrement. Enfin, il crée un processus fils pour démarrer l'enregistrement. Voir section~\ref{par:capture} pour le détail de fonctionnement de la capture vidéo à l'aide du programme \texttt{ffmpeg}.
    \item \textbf{Détection de mouvement} : Commandes de détection (\texttt{detc}) pour analyser les images et suivre les mouvements. Cet ordre fait appel à la fonction \texttt{processusDetection} qui crée un processus fils pour effectuer la détection de mouvement. Voir section~\ref{par:detection} pour le détail de fonctionnement de la détection de mouvement.
    \item \textbf{Enregistrement vidéo} : Commandes d'enregistrement (\texttt{enrg}) pour démarrer ou arrêter un processus d'enregistrement vidéo. Ce ordre vient lancer un processus de capture vidéo et de détection de mouvement.
    \item \textbf{Gestion des positions prédéfinies} : Commandes (\texttt{rout}) pour ajouter, supprimer ou afficher des positions prédéfinies, voir le paragraph suivant pour plus d'informations.
    \item \textbf{Changement de caméra active} : Commandes (\texttt{cam}) pour basculer entre les caméras configurées.
\end{itemize}

\paragraph{Gestion des positions prédéfinies} 
Le fichier \texttt{positions.c} est responsable de la gestion des positions des caméras PTZ et des voies associées. Il permet d'ajouter, de supprimer et d'afficher des positions prédéfinies en interagissant avec un fichier JSON pour stocker les données. Les fonctions principales de ce fichier sont \texttt{addRoute}, \texttt{removeRoute} et \texttt{showRoute}.

\subparagraph{Ajout d'une route : \texttt{addRoute}}

La fonction \texttt{addRoute} permet d'ajouter une nouvelle position PTZ associée à une voie dans le fichier JSON. Voici les étapes principales de son fonctionnement :
\begin{enumerate}
    \item \textbf{Récupération de la position actuelle de la caméra} :
    La fonction \texttt{recupererPosition} est appelée pour obtenir les valeurs actuelles de \texttt{pan}, \texttt{tilt} et \texttt{zoom} de la caméra active via une requête HTTP. Pour cela, une URL est construite avec les informations de la caméra et envoyée à l'aide de la bibliothèque \texttt{libcurl} permettant d'afficher sur une page HTML les données de la caméra. Enfin, les données retournées par la caméra sont analysées pour extraire les valeurs de \texttt{pan}, \texttt{tilt} et \texttt{zoom}.
    \item \textbf{Ajout de la position dans le fichier JSON} :
    La fonction \texttt{addPositionFile} est appelée pour insérer les valeurs récupérées dans le fichier JSON. Si le fichier JSON n'existe pas, il est créé. Une nouvelle entrée est ajoutée sous la forme d'un tableau contenant les valeurs de \texttt{pan}, \texttt{tilt}, \texttt{zoom} et l'identifiant de la caméra.
\end{enumerate}


\subparagraph{Suppression d'une route : \texttt{removeRoute}}

La fonction \texttt{removeRoute} permet de supprimer une position PTZ associée à une voie dans le fichier JSON. Voici les étapes principales de son fonctionnement :
\begin{enumerate}
    \item \textbf{Chargement du fichier JSON} :
        Le fichier JSON contenant les positions PTZ est chargé en mémoire à l'aide de la bibliothèque \texttt{jansson}.

    \item \textbf{Suppression de la clé associée à la voie} :
        La clé correspondant à la voie spécifiée est supprimée du fichier JSON à l'aide de la fonction \texttt{json\_object\_del}.
    
    \item \textbf{Sauvegarde du fichier JSON modifié} :
        Le fichier JSON est mis à jour et sauvegardé sur le disque. 
    
\end{enumerate}


\subparagraph{Affichage d'une route : \texttt{showRoute}}

La fonction \texttt{showRoute} permet d'afficher les informations d'une position PTZ associée à une voie et de déplacer la caméra vers cette position. Voici les étapes principales de son fonctionnement :
\begin{enumerate}
    \item \textbf{Chargement du fichier JSON} :
        Le fichier JSON contenant les positions PTZ est chargé en mémoire à l'aide de la bibliothèque \texttt{jansson}. 
        

    \item \textbf{Récupération des données de la voie} :
        Les données associées à la voie spécifiée sont extraites du fichier JSON.
        Ces données incluent les valeurs de \texttt{pan}, \texttt{tilt}, \texttt{zoom} et l'identifiant de la caméra. Si la voie n'existe pas ou si les données sont invalides, un message d'erreur est affiché, et la fonction retourne \texttt{-1}.
    
    \item \textbf{Déplacement de la caméra} :
        Si la caméra active n'est pas celle spécifiée dans les données, la fonction \texttt{setActiveCamera} est appelée pour activer la caméra correspondante.  fonction \texttt{allerPosition} est appelée pour envoyer une requête HTTP à la caméra afin de la déplacer vers la position spécifiée.
    
\end{enumerate}



\paragraph{Libération des ressources}
Lorsque le programme se termine, la fonction \texttt{bye()} est appelée pour libérer toutes les ressources :
\begin{itemize}
    \item Les processus enfants encore actifs sont arrêtés.
    \item Les segments de mémoire partagée sont détachés et supprimés.
    \item Les sémaphores sont fermés et supprimés.
\end{itemize}

%-----------------------------------------------------------

\subsubsection{\'Ecriture mémoire}

Le fichier \texttt{ecritureMemoire.cpp} est un processus dédié à la capture des images vidéo depuis une source donnée (on exécute le programme avec comme argument l'url de vidéo) et à leur écriture dans un segment de mémoire partagée. Ce processus est essentiel pour permettre la communication inter-processus entre les différents modules du système.

\paragraph{Initialisation du programme}
Lors de son démarrage, le programme effectue plusieurs étapes d'initialisation :
\begin{itemize}
    \item \textbf{Gestionnaire de signaux} : Le programme installe un gestionnaire de signaux (\texttt{signalHandler}) pour gérer les interruptions (\texttt{SIGINT}) et les arrêts (\texttt{SIGTERM}) de manière propre.
    \item \textbf{Ouverture des sémaphores} \label{par:semaphores}: Les sémaphores nommés sont ouverts pour synchroniser l'accès à la mémoire partagée entre les processus :
    \begin{itemize}
        \item \texttt{SEM\_READERS} : Compte les lecteurs actifs.
        \item \texttt{SEM\_WRITER} : Contrôle l'accès en écriture à la mémoire partagée.
        \item \texttt{SEM\_NEW\_FRAME} : Indique qu'une nouvelle image est disponible.
        \item \texttt{SEM\_ACTIVE\_READERS} : Compte les lecteurs actifs qui attendent une nouvelle image.
        \item \texttt{SEM\_MUTEX} : Protège l'accès aux compteurs de sémaphores.
    \end{itemize}
    \item \textbf{Ouverture de la mémoire partagée} : Le segment de mémoire partagée est ouvert et mappé en mémoire virtuelle pour permettre l'écriture des images capturées.
\end{itemize}

\paragraph{Capture vidéo}
Le programme utilise OpenCV pour capturer les images vidéo depuis la source spécifiée en argument :
\begin{itemize}
    \item \textbf{Initialisation de la capture vidéo} : La capture est ouverte avec \texttt{cv::VideoCapture} en sur l'URL de l'argument passé au programme. Les propriétés de la capture sont configurées pour être sur les même paramètres que la source vidéo.
    \item \textbf{Vérification de la capture} : Si la capture ne peut pas être ouverte, le programme affiche une erreur et se termine.
\end{itemize}

\paragraph{Boucle principale}
Le programme entre dans une boucle principale pour capturer les images et les écrire dans la mémoire partagée :
\begin{itemize}
    \item \textbf{Capture d'une image} : Une image est capturée à l'aide de \texttt{cap.read(frame)}. Si la capture échoue, le programme affiche une erreur et quitte la boucle.
    \item \textbf{Écriture dans la mémoire partagée} : Le sémaphore \texttt{SEM\_WRITER} est utilisé pour bloquer l'accès en écriture pendant que l'image est copiée dans la mémoire partagée. Les données de l'image sont copiées avec \texttt{std::memcpy}.
    \item \textbf{Notification des lecteurs} : Le programme utilise le sémaphore \texttt{SEM\_NEW\_FRAME} pour notifier tous les lecteurs actifs (\texttt{SEM\_ACTIVE\_READERS}) qu'une nouvelle image est disponible.
\end{itemize}

\paragraph{Libération des ressources}
Lorsque le programme se termine (par un signal ou une erreur), il libère toutes les ressources utilisées :
\begin{itemize}
    \item \textbf{Libération de la mémoire partagée} : Le segment de mémoire partagée est détaché (\texttt{munmap}) et fermé (\texttt{close}).
    \item \textbf{Fermeture des sémaphores} : Tous les sémaphores ouverts sont fermés avec \texttt{sem\_close}.
    \item \textbf{Libération de la capture vidéo} : La capture vidéo est libérée avec \texttt{cap.release}.
\end{itemize}

\paragraph{Gestion des signaux}
Le gestionnaire de signaux (\texttt{signalHandler}) permet de gérer les interruptions et les arrêts du programme :
\begin{itemize}
    \item \textbf{SIGINT} : Interrompt immédiatement le programme.
    \item \textbf{SIGTERM} : Arrête proprement le programme en mettant fin à la boucle principale.
\end{itemize}



%-----------------------------------------------------------
\subsubsection{Détection de mouvement} \label{par:detection}

Le fichier \texttt{detection.cpp} est un programme dédié à la détection de mouvements dans un flux vidéo et au contrôle des caméras PTZ en fonction des mouvements détectés. Il utilise OpenCV pour le traitement des images, des sémaphores pour la synchronisation entre processus, et la mémoire partagée pour accéder aux images brutes.


\paragraph{Initialisation du programme}
Lors de son démarrage, le programme effectue plusieurs étapes d'initialisation :
\begin{itemize}
    \item \textbf{Gestionnaire de signaux} :
    \begin{itemize}
        \item Le programme installe un gestionnaire de signaux (\texttt{signalHandler}) pour gérer les interruptions (\texttt{SIGINT}) et les arrêts (\texttt{SIGTERM}) de manière propre.
        \item En cas de réception d'un signal, le programme termine la détection en cours et libère les ressources.
    \end{itemize}
    \item \textbf{Chargement des paramètres de la caméra active} : 
    \begin{itemize}
        \item Les paramètres de la caméra active (IP, orientation, dimensions, commandes PTZ, etc.) sont chargés depuis un fichier JSON, que le programme principal met à jour à chaque changement de caméra.
        \item Récupération du zoom actuel de la caméra pour ajuster les commandes PTZ en fonction du niveau de zoom, via une requête HTTP.
    \end{itemize}
    \item \textbf{Chargement des paramètres de détection} : 
        Les paramètres de détection (seuils verticaux et horizontaux, coefficients de flou gaussien, etc.) sont également chargés depuis un fichier JSON, nommé \texttt{PATH\_PARAM\_DETECTION}. Cela permet de modifier facilement les paramètres de détection sans recompiler le programme. Le détail des paramètres dont une description est présentée ci contre :


    \begin{itemize}
        \item \textbf{\texttt{framesBetweenReferences}} : Nombre d'images entre deux actualisations de l'image de référence utilisée pour la détection de mouvement.
        
        \item \textbf{\texttt{verticalThreshold}} : Seuil vertical utilisé pour détecter les mouvements dans la zone de détection. Définit la fraction de la hauteur de la zone de détection où un mouvement est considéré comme un déplacement vertical (haut seulement).

        \item \textbf{\texttt{horizontalThreshold}} : Seuil horizontal utilisé pour détecter les mouvements dans la zone de détection. Définit la fraction de la largeur de la zone de détection où un mouvement est considéré comme un déplacement horizontal (gauche ou droite).

        \item \textbf{\texttt{coefAverageMovingFilter}} : Coefficient du filtre de moyenne glissante appliqué au barycentre des mouvements détectés. 

        \item \textbf{\texttt{coefGaussianBlur}} : Taille du noyau utilisé pour appliquer un flou gaussien aux images. 

        \item \textbf{\texttt{heightResizeRatio}} et \textbf{\texttt{widthResizeRatio}} : Facteurs de redimensionnement pour réduire la taille des images avant le traitement. 

        \item \textbf{\texttt{nbMoveBeforeChangeDetectionArea}} : Nombre de mouvements verticaux nécessaires avant de modifier la position de la zone de détection. 

        \item \textbf{\texttt{cropRatioDetectionAreaLandscape}} et \textbf{\texttt{cropRatioDetectionAreaPortrait}} : Ratios utilisés pour définir la taille et la position de la zone de détection en fonction de l'orientation de la caméra (paysage ou portrait). Les zones de detection diffèrent en fonction de l'orientation de l'image pour assurer un detection optimale.

        \item \textbf{\texttt{numberFrameBetweenMove}} : Nombre minimum d'images entre deux mouvements consécutifs de la caméra. Empêche la caméra de se déplacer trop fréquemment, ce qui pourrait entraîner des oscillations.

        \item \textbf{\texttt{numberFrameWithoutMove}} : Nombre d'images sans mouvement détecté avant d'arrêter automatiquement la détection. 
        
        \item \textbf{\texttt{increasePTZ}} : Facteur d'augmentation utilisé pour ajuster les commandes PTZ en fonction du zoom actuel de la caméra. Permet de compenser les mouvements en fonction du niveau de zoom pour maintenir une précision constante.
    \end{itemize}

    \item \textbf{Ouverture des sémaphores et de la mémoire partagée} :
    \begin{itemize}
        \item Les sémaphores nécessaires à la synchronisation entre processus sont ouverts.
        \item Le segment de mémoire partagée contenant les images brutes est ouvert et mappé en mémoire virtuelle.
    \end{itemize}
\end{itemize}

\paragraph{Boucle principale}
Le programme entre dans une boucle principale pour analyser les images et détecter les mouvements :
\begin{itemize}
    \item \textbf{Lecture des images depuis la mémoire partagée} : Les images brutes sont lues depuis la mémoire partagée en utilisant les sémaphores pour garantir une synchronisation correcte.
    \item \textbf{Prétraitement des images} :
    \begin{itemize}
        \item Les images sont redimensionnées, leur taille est divisé par deux pour accélérer le traitement.
        \item Ensuite l'image est converties en niveaux de gris
        \item Puis, on applique une égalisation d'histogramme à l'image en niveaux de gris. Afin d'améliorer le contraste de l'image en redistribuant les intensités des pixels.
        \item Enfin, un flou gaussien est appliqué pour réduire le bruit dûs à de faible mouvement, comme par exemple la corde qui bouge. Voir les images en noir et blanc sur la figure~\ref{fig:detectionArea}.
    \end{itemize}
    \item \textbf{Détection des mouvements} :
    \begin{itemize}
        \item Une image de référence est utilisée pour calculer la différence absolue avec l'image actuelle. L'image de référence est actualisée toutes les 5 images, ou dès lors que la caméra est déplacée.
        \item Un seuil binaire est appliqué pour identifier les zones de mouvement. L'image est donc devenu une image binaire avec des pixels à 0 pour les zones sans mouvement et à 255 pour les zones avec mouvement.
        \item Une zone de détection est définie pour limiter l'analyse à une partie spécifique de l'image. Au démarrage, la zone de détection est sur le haut de l'image, voir le rectangle vert figure~\ref{fig:detectionDeBase}. Après que la caméra se soit déplacée vers le haut, la zone de détection est déplacée vers le bas, voir figure~\ref{fig:detectionHautPremier}. Après, la zone de détection reste fixe pour tout le reste du suivi du grimpeur, voir figure~\ref{fig:detectionHautSecond}.
        
        Il est nécessaire de changer la zone de détection car en bas d'une voie, l'algorithme de détection ne sait pas faire la distinction entre le grimpeur et l'assureur. Donc on regarde que le haut de l'écran au début avant de recentrer la zone de détection sur le centre de l'image.

        \item Les moments de la zone de détection sont calculés pour déterminer le barycentre du mouvement. On applique un filtre de moyenne glissante de coefficient 0.4 pour lisser les mouvements.
    \end{itemize}

    \item \textbf{Analyse des mouvements} :
    \begin{itemize}
        \item Si le barycentre se trouve dans une zone spécifique, un mouvement est détecté :
        \begin{itemize}
            \item \textbf{Mouvement vertical} : Si le barycentre est dans la partie supérieure la caméra est déplacée vers le haut, voir lignes rouges horizontales sur les figures~\ref{fig:detectionArea}. La caméra est déplacée vers le haut si le barycentre se trouve entre la ligne rouge et la ligne verte du haut de l'image.
            \item \textbf{Mouvement horizontal} : Si le barycentre est dans la partie gauche ou droite de la zone de détection, la caméra est déplacée vers la gauche ou la droite. voir lignes rouges verticales sur les figures~\ref{fig:detectionArea}.
        \end{itemize}
        \item Les commandes PTZ sont envoyées à la caméra via des requêtes HTTP, comme pour le programme principal.
    \end{itemize}
    \item \textbf{Arrêt de la détection} :
    \begin{itemize}
        \item Si aucun mouvement n'est détecté pendant un certain nombre de frames, la détection s'arrête automatiquement.
    \end{itemize}
\end{itemize}

%% TODO
\paragraph{Libération des ressources}
À la fin du programme, toutes les ressources utilisées sont libérées :
\begin{itemize}
    \item \textbf{Fermeture des sémaphores} : Tous les sémaphores ouverts sont fermés avec \texttt{sem\_close}.
    \item \textbf{Libération de la mémoire partagée} : Le segment de mémoire partagée est détaché (\texttt{munmap}) et fermé (\texttt{close}).
    \item \textbf{Fermeture des fenêtres OpenCV} : Toutes les fenêtres créées pour l'affichage des résultats sont fermées avec \texttt{cv::destroyAllWindows}.
\end{itemize}

\paragraph{Gestion des signaux}
Le gestionnaire de signaux (\texttt{signalHandler}) permet de gérer les interruptions et les arrêts du programme :
\begin{itemize}
    \item \textbf{SIGTERM} : Arrête proprement le programme en mettant fin à la boucle principale.
    \item \textbf{SIGINT} : Interrompt immédiatement le programme.
\end{itemize}


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{detectionDeBase.png}
      \caption{Initialisation des zones de détection}
      \label{fig:detectionDeBase}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{detectionHautPremier.png}
      \caption{Zone avant premier mouvement vertical}
      \label{fig:detectionHautPremier}
    \end{subfigure}

    \vspace*{7mm}

    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{detectionHautSecond.png}
        \caption{Zones après premier mouvement vertical}
        \label{fig:detectionHautSecond}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{detectionHautTroisieme.png}
        \caption{Zone après second mouvement vertical}
        \label{fig:detectionHautTroisieme}
    \end{subfigure}

    \vspace*{7mm}

    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{detectionDroite.png}
        \caption{Détection sur la droite}
        \label{fig:detectionDroite}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{detectionGauche.png}
        \caption{Détection sur la gauche}
        \label{fig:detectionGauche}
    \end{subfigure}

    \caption{Zones de détection de mouvement}
    \label{fig:detectionArea}
  \end{figure}


%------------------------------------------------------------
\subsubsection{Capture vidéo} \label{par:capture}

Le fichier \texttt{enregistrementVideo.c} est un programme dédié à l'enregistrement des flux vidéo provenant de la mémoire partagée. Il utilise des sémaphores pour la synchronisation entre processus, la mémoire partagée pour l'accès aux images brutes, et \texttt{FFmpeg}\footnote{FFmpeg est une suite logicielle open-source puissante et polyvalente utilisée pour manipuler des fichiers multimédias (audio et vidéo). Elle permet de réaliser des tâches telles que la conversion de formats, l'encodage, le décodage, le montage, le streaming, et bien plus encore. Pour plus d'information voir \href{https://ffmpeg.org/ffmpeg.html}{la documentation en ligne}} pour encoder les vidéos dans un format compressé. Ce programme est conçu pour fonctionner de manière autonome et s'arrêter proprement en cas de signal d'interruption.


\paragraph{Initialisation du programme}
Lors de son démarrage, le programme effectue plusieurs étapes d'initialisation :
\begin{itemize}
    \item \textbf{Gestionnaire de signaux} : 
    \begin{itemize}
        \item Le programme installe un gestionnaire de signaux (\texttt{signalHandler}) pour gérer les interruptions (\texttt{SIGINT}) et les arrêts (\texttt{SIGTERM}) de manière propre.
        \item En cas de réception d'un signal, le programme termine l'enregistrement en cours et libère les ressources.
    \end{itemize}
    \item \textbf{Ouverture des sémaphores} :
    \begin{itemize}
        \item Les sémaphores nommés (\texttt{SEM\_READERS}, \texttt{SEM\_WRITER}, \texttt{SEM\_NEW\_FRAME}, etc.) sont ouverts pour synchroniser l'accès à la mémoire partagée entre les processus.
        \item Le compteur de lecteurs actifs (\texttt{SEM\_ACTIVE\_READERS}) est incrémenté pour indiquer qu'un nouveau lecteur est actif.
    \end{itemize}
    \item \textbf{Ouverture de la mémoire partagée} :
    \begin{itemize}
        \item Le segment de mémoire partagée contenant les images brutes est ouvert et mappé en mémoire virtuelle pour permettre la lecture des images.
    \end{itemize}
    \item \textbf{Préparation de la commande FFmpeg} :
    Afin d'optimiser l'utilisation de FFmpeg, on utilise sur le raspberry l'accélération matériel pour l'encodage vidéo. Pour cela, on utilise l'encoder \texttt{v4l2m2m} qui permet d'utiliser le codec H.264 pour l'encodage vidéo. La commande FFmpeg est construite pour encoder les images brutes en vidéo compressée. 
    \begin{itemize}
        \item \texttt{-f rawvideo} : Spécifie que l'entrée est une vidéo brute.
        \item \texttt{fflags +discardcorrupt+genpts} : Ignore les images corrompues et génère des horodatages.
        \item \texttt{-pixel\_format bgr24} : Définit le format des pixels en BGR 24 bits.
        \item \texttt{-s 1280x720} : Définit la résolution d'entrée.
        \item \texttt{-r 25} : Définit le débit d'images d'entrée (25 FPS).
        \item \texttt{-framerate 25} : Force le débit d'image sortant (25 FPS).
        \item \texttt{-c:v h264\_v4l2m2m} : Utilise le codec H.264 pour l'encodage et l'acceleration matérielle sur le rpi. Sur une architechture x86, on peut utiliser \texttt{-c:v libx264} pour l'encodage.
        \item \texttt{-pix\_fmt yuv420p} : Définit le format des pixels en YUV 4:2:0. Ce format est optimisé pour lire les vidéos sur navigateur web.
        \item \texttt{-b:v 5M} : Définit le débit binaire de sortie à 5 Mbit/s (Meilleur débit pour de la 720p).
        \item \texttt{-an} : Désactive l'audio.
    \end{itemize}
\end{itemize}



\paragraph{Boucle principale}
Le programme entre dans une boucle principale pour capturer les images et les écrire dans le pipe standard de \texttt{FFmpeg} :
\begin{itemize}
    \item \textbf{Attente d'une nouvelle image} :
    \begin{itemize}
        \item Le programme attend qu'une nouvelle image soit disponible en utilisant le sémaphore \texttt{SEM\_NEW\_FRAME}.
    \end{itemize}
    \item \textbf{Synchronisation avec les sémaphores} :
    \begin{itemize}
        \item Le sémaphore \texttt{SEM\_WRITER} est utilisé pour bloquer l'accès en écriture pendant que l'image est lue.
        \item Le sémaphore \texttt{SEM\_READERS} est utilisé pour indiquer qu'un nouveau lecteur est en cours de lecture.
    \end{itemize}
    \item \textbf{Écriture dans le pipe FFmpeg} :
    \begin{itemize}
        \item L'image brute est lue depuis la mémoire partagée et écrite dans le pipe standard de \texttt{FFmpeg} à l'aide de la fonction \texttt{fwrite}. L'image est encodé dans une vidéo temporaire en attendant la fin de l'enregistrement.
    \end{itemize}
\end{itemize}


\paragraph{Découpage de la vidéo}
Une fois l'enregistrement terminé, la fonction \texttt{decouperVideo} est appelée pour découper la vidéo et ne conserver que la partie intéressante :
\begin{itemize}
    \item \textbf{Lecture des frames de début et de fin} :
    \begin{itemize}
        \item Les frames de début et de fin sont lues depuis un fichier (\texttt{PATH\_FRAMES}), qui sont écrites à la fin du processus de détection de mouvement.
        \item Si le fichier n'existe pas, des valeurs par défaut sont utilisées.
    \end{itemize}
    \item \textbf{Ajustement des frames} :
    \begin{itemize}
        \item Les frames sont ajustées en fonction des paramètres définis, comme le nombre de frames avant le premier mouvement ou après l'absence de mouvement afin de garder une partie de la video juste avant le premier mouvement de la caméra. 
    \end{itemize}
    \item \textbf{Exécution de la commande FFmpeg} :
    \begin{itemize}
        \item Une commande \texttt{FFmpeg} est construite pour découper la vidéo en fonction des frames ajustées et si besoin la réorienter dans le bon sens en fonction de l'orientation de la caméra.
        \item La vidéo temporaire (\texttt{VIDEO\_TEMP}) est utilisée comme entrée, et la vidéo finale est sauvegardée avec un nom personnalisé construit par le programme principal.
    \end{itemize}
\end{itemize}

\paragraph{Libération des ressources}
À la fin du programme, toutes les ressources utilisées sont libérées :
\begin{itemize}
    \item \textbf{Fermeture des sémaphores} : Tous les sémaphores ouverts sont fermés avec \texttt{sem\_close}.
    \item \textbf{Libération de la mémoire partagée} : Le segment de mémoire partagée est détaché (\texttt{munmap}) et fermé (\texttt{close}).
    \item \textbf{Fermeture du pipe FFmpeg} Le pipe standard vers \texttt{FFmpeg} est fermé avec \texttt{pclose}.
\end{itemize}


\paragraph{Gestion des signaux}
Le gestionnaire de signaux (\texttt{signalHandler}) permet de gérer les interruptions et les arrêts du programme :
\begin{itemize}
    \item \textbf{SIGTERM} : Arrête proprement le programme en mettant fin à la boucle principale.
    \item \textbf{SIGINT} : Interrompt immédiatement le programme.
\end{itemize}

%-----------------------------------------------------------

\subsection{Application web}
Le serveur web est composée de deux pages web voir figure~\ref{fig:pagesWeb}, la première permet de visualiser le flux vidéo de la caméra, de la piloter et de piloter l'application. La seconde permet de visualiser les vidéos enregistrées et de les télécharger, le code de ces pages est écrit en \texttt{HTML}, \texttt{CSS} et \texttt{JAVASCRIPT} peut-être consulté sur la page \href{https://github.com/Romaiiin91/suiviGrimpeur_PDI/tree/main/server/html}{GitHub}.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{pageIndex.png}
    \caption{Index de l'application}
    \label{fig:pageIndex}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{pageVideo.png}
    \caption{Page web de visualisation des vidéos}
    \label{fig:pageVideo}
  \end{subfigure}
  \caption{Pages web de l'application}
  \label{fig:pagesWeb}
\end{figure}

\subsubsection{Page web index (figure~\ref{fig:pageIndex})}
Au chargement de cette page, une fonction \texttt{javascript} permet de charger les voies disponibles dans la base de données et de les ajouter dans une liste déroulante pour permettre à l'utilisateur de sélectionner la voie qu'il souhaite visualiser. Une seconde fonction \texttt{js} charge les caméras disponibles et les ajoute dans une seconde liste déroulante. Puis le script \texttt{video.cgi} est exécuté pour afficher le flux vidéo de la caméra sélectionnée.

Le processus lit dans la mémoire partagée les images brutes a l'aide d'\texttt{OPENCV} pour récupérer une matrice de pixel, puis le profil colorimétrique de l'image est changé car \texttt{OPENCV} travaille en \textit{BGR (blue green red)} et le \texttt{JPEG} utilise un profil (\textit{RGB (red green blue)}) puis est encodé en \texttt{JPEG} à l'aide de la librairie \texttt{libjpeg}. Enfin, on ajoute les entêtes \texttt{HTTP} pour que le navigateur puisse interpreter l'image et on écrit l'image encodée dans la sortie standard.

Sur la gauche de cette page, on retrouve tout les boutons de contrôle de la caméra (haut, bas, gauche et droite) associé à un curseur pour la précision de l'angle afin de premettre un déplacement plus précis. On retrouve un second curseur pour gérer le zoom de la caméra entre 1x et 18x. La pression de l'un de ses boutons créent une requête \texttt{AJAX} pour exécuter le script \texttt{action.cgi} qui va écrire dans la mémoire partagée l'action à effectuer puis réveiller le programme principal pour qu'il effectue l'action et attendre le feedback du main ou un timeout de 5 secondes avec l'intruction \texttt{SIGALRM} (il récupère le pid du main dans un fichier que ce dernier crée au démarrage). Finalement, il envoie une réponse \texttt{HTTP} pour indiquer que l'action a bien été effectuée.

En dessous de ces curseurs, il y a une liste déroulante pour choisir la voie que l'on souhaite observer. À la selection d'une voie on vient changer de caméra si besoin et la positionner au bon endroit.

En dessous de la video, on retrouve un bouton pour enregistrer une vidéo avec deux champ pour entre le nom et prenom du grimpeur, un exemple de requête \texttt{AJAX} est présenté ci-contre : \texttt{http://localhost/cgi-bin/action.cgi?enrg=on\&nom=Chevalier\&prenom=Romain\&voie=0}. On récupère le nom et la voie afin de produire un nom de fichier unique et pouvoir le récupérer facilement dans la page de visualisation des vidéos.

\paragraph{Paramètres avancés}  En bas de page, on trouve les options pour configurer une nouvelle voie. Il y a une liste déroulante pour choisir la caméra, puis une seconde liste déroulante pour choisir une voie que l'on souhaite supprimer ou afficher sur l'appuie du bouton adéquat. Il y a également un bouton pour sauvegarder une nouvelle position de la caméra dans la base de données en affichant une fenêtre popup pour demander le numéro de voie. 
En addition, on peut également lancer ou stop un enregistrement seul sans suivi du grimpeur et à l'inverse, on peut lancer seulement et stopper la détection du grimpeur sans enregistrement.

\subsubsection{Page web de visualisation des vidéos (figure~\ref{fig:pageVideo})}
Cette page permet de visualiser les vidéos enregistrées, de les télécharger et de les supprimer. Elles sont répertoriées dans un tableau avec le nom du grimpeur, la voie, la date et l'heure de l'enregistrement. On peut, de plus, rechercher une video particulière à l'aide de la barre de recherche en haut de page. Avec les fonction du navigateur, on peut lire, mettre en pause, accélérer, ralentir ou télécharger la vidéo. Enfin, on peut voir la video en haut de page en cliquant sur \texttt{voir}, la visionnier dans un nouvel onglet en cliquant sur \texttt{visionnier} ou la supprimer en cliquant sur \texttt{supprimer}.








\subsection{Problèmes rencontrés}








%-----------------------------------------------------------
\section{Tests et résultats}

\section{Perspectives d'amélioration}
\begin{itemize}
  \item Amélioration de l'interface Web, avoir une interface plus intuitive et plus ergonomique.
  \item Reformater le code et tout traduire en anglais
  \item Afficher sur l'écran du Raspberry Pi, un meilleur status de l'execution de l'application.
  \item Utiliser les boutons du Raspberry Pi pour relancer l'application.
  \item Ajouter un système de notification pour les erreurs.
  \item Mieux gérer le stockage des vidéos.
  \item Ajouter un système de détection de chute.
\end{itemize}








%-----------------------------------------------------------
% \clearpage
% \newpage


% \section*{Annexes}
% \addcontentsline{toc}{section}{Annexes}

% \appendix

% \startcontents[sections]
% \printcontents[sections]{l}{1}{\setcounter{tocdepth}{2}}


%     \section{Glossaire}
      




\end{document}